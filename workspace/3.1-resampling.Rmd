---
title: "Walidacja krzyżowa i bootstrap"
date: "Semestr letni 2023/24"
output: html_document
---

## Ładowanie zbioru danych

```{r}
df = read.csv("spotify-2023.csv")
names(df)[names(df) == "danceability_."] <- "danceability"
names(df)[names(df) == "valence_."] <- "valence"
names(df)[names(df) == "energy_."] <- "energy"
names(df)[names(df) == "acousticness_."] <- "acousticness"
names(df)[names(df) == "instrumentalness_."] <- "instrumentalness"
names(df)[names(df) == "liveness_."] <- "liveness"
names(df)[names(df) == "speechiness_."] <- "speechiness"

df = transform(df, streams = as.numeric(streams))

library(class)
library(MASS)
head(df)
```

## Walidacja krzyżowa

Usuwamy NA
```{r}
df <- na.omit(df)
```

### Metoda zbioru walidacyjnego

Tworzymy zbiór uczący z połowy dostępnych obserwacji --- reszta będzie stanowić
zbiór walidacyjny. Dla zapewnienia powtarzalności obliczeń stosujemy funkcję
`set.seed`.
```{r}
set.seed(1)
n <- nrow(df)
train <- sample(n, n / 2)
```

Dopasowujemy model liniowy na zbiorze uczącym, następnie obliczamy MSE dla zbioru
walidacyjnego.
```{r}
df_lm <- lm(streams ~ liveness, data = df, subset = train)
validation_set <- df[-train,]
mse <- mean((validation_set$streams - predict(df_lm, validation_set))^2)
mse
```

Powtarzamy to samo dla regresji wielomianowej wyższych stopni
```{r}
for (i in 2:5) {
  df_lm_poly <- lm(streams ~ poly(liveness, degree = i), data = df, 
                     subset = train)
  print(mean((validation_set$streams - predict(df_lm_poly, validation_set))^2))
}
```

[**Jaki z tych wyników można wyciągnąć wniosek?**]
Ciężko wnioskować liczbę odsłuchań na podstawie tego czy piosenka jest wyknoywana na żywo. A jeśli juz musimy to lepiej użyć niskiego współczynnika wielomianu

Powtarzamy obliczenia dla innego zbioru walidacyjnego.
```{r}
set.seed(2)
train <- sample(n, n / 2)
validation_set <- df[-train,]
degree_max <- 5
mse <- rep(0, times = degree_max)
for (i in 1:degree_max) {
  df_lm <- lm(streams ~ poly(liveness, degree = i), data = df, subset = train)
  mse[i] <- mean((validation_set$streams - predict(df_lm, validation_set))^2)
}
mse
```
Nieco inne wyniki - oczekiwane

Wersja powyższego obliczenia dla miłośników programowania funkcyjnego i tych,
którzy nie lubią pętli.
```{r}
compute_mse <- function(degree, train) {
  df_lm <- lm(streams ~ poly(liveness, degree), data = df, subset = train)
  validation_set <- df[-train,]
  mean((validation_set$streams - predict(df_lm, validation_set))^2)
}

mse <- sapply(1:degree_max, compute_mse, train = train)
mse
```
Funkcja `vapply` jest bezpieczniejsza i bywa szybsza od `sapply`, więc
przedostatnią instrukcję można zmodyfikować następująco:
```{r}
mse <- vapply(1:degree_max, compute_mse, FUN.VALUE = numeric(1), train = train)
```

Otrzymane wyniki można zobrazować na wykresie
```{r}
plot(mse, xlab = "Stopień wielomianu", ylab = "MSE", type = "b", pch = 20, 
     col = "blue")
```

[**Czy teraz wcześniejsze wnioski ulegają zmianie?**]

### Walidacja krzyżowa _bez jednego_ (*leave-one-out*)

Walidację krzyżową dla uogólnionych modeli liniowych wykonuje funkcja `cv.glm()`
z pakietu `boot`. Jej argumentem (`glmfit`) jest obiekt klasy `glm`, więc
jeśli chcemy jej użyć do walidacji zwykłych modeli liniowych, musimy je dopasowywać
jako uogólnione modele liniowe (z `family = gaussian`, co zresztą jest wartością
domyślną). Funkcja `cv.glm()` zwraca listę (zobacz `?cv.glm`), której najbardziej
interesującą składawą jest `delta` --- wektor o długości 2 zawierający estymatę
błędu predykcji w wersji oryginalnej i skorygowaną dla uwzględnienia obciążenia
wprowadzanego przez walidację krzyżową inną niż LOOCV.
```{r}
library(boot)

compute_loocv_mse <- function(degree) {
  df_glm <- glm(streams ~ poly(liveness, degree), data = df)
  cv.glm(df, df_glm)$delta[1]
}
mse <- sapply(1:degree_max, compute_loocv_mse)
mse
```

Można też narysować obrazek
```{r}
plot(mse, xlab = "Stopień wielomianu", ylab = "LOOCV MSE", type = "b", pch = 20, 
     col = "blue")
```

[**Co teraz z wnioskami na temat regresji wielomianowej w naszym przypadku?**]

MSE jest jeszcze gorsze.

[**Sprawdź, że dla LOOCV obie współrzędne `delta` zawierają praktycznie to samo.**]

### $k$-krotna walidacja krzyżowa

Podobnie korzystamy z funkcji `cv.glm()`, tylko teraz jawnie ustawiamy parametr `K`
oznaczający liczbę grup (*folds*). Np. dla $k = 10$ wygląda to jak poniżej.
```{r kcv}
compute_kcv_mse <- function(degree, k) {
  df_glm <- glm(streams ~ poly(liveness, degree), data = df)
  cv.glm(df, df_glm, K = k)$delta[1]
}
mse <- sapply(1:degree_max, compute_kcv_mse, k = 10)
mse
```

Oczywiście tym razem wyniki są losowe. Możemy zrobić ich zestawienie
dla np. 10 prób.
```{r kcv2}
mse10 <- replicate(10, sapply(1:degree_max, compute_kcv_mse, k = 10))
mse10
```

I stosowny obrazek
```{r}
matplot(mse10, pch = 20, type = "l", xlim = c(1, degree_max), ylim = c(18, 25),
        xlab = "Stopień wielomianu", ylab = "Walidacyjny MSE")
```

[**Co teraz z wnioskami?**]

## Bootstrap

Użyjemy metody *bootstrap* do oszacowania błędów standardowych współczynników
regresji liniowej. Podstawową funkcją jest tutaj `boot()` z pakietu `boot`.
Wymaga ona jako parametru funkcji obliczającej interesującą statystykę dla podanego 
zbioru danych. Ta ostatnia funkcja powinna akceptować dwa parametry: zbiór danych
oraz wektor indeksów (istnieją też inne możliwości: `?boot`).
```{r}
lm_coefs <- function(data, index = 1:nrow(data)) {
  coef(lm(streams ~ liveness, data = df, subset = index))
}
```

Funkcja `lm_coefs()` oblicza estymaty współczynników regresji dla zbioru danych
typu bootstrap utworzonego z `Auto`:
```{r}
n <- nrow(df)
lm_coefs(df, sample(n, n, replace = TRUE))
```
Oczywiście jednym z takich zbiorów jest sam oryginał
```{r}
lm_coefs(df)
```

Obliczenie błędów standardowych metodą bootstrap z 1000 replikacji wygląda 
następująco.
```{r boot}
boot(df, lm_coefs, R = 1000)
```

