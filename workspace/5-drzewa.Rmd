---
title: "Drzewa decyzyjne i modele pochodne"
date: "Semestr letni 2021/22"
output: html_document
---

## Ładowanie zbioru danych

```{r}
dataframe = read.csv("spotify-2023.csv")
names(dataframe)[names(dataframe) == "danceability_."] <- "danceability"
names(dataframe)[names(dataframe) == "valence_."] <- "valence"
names(dataframe)[names(dataframe) == "energy_."] <- "energy"
names(dataframe)[names(dataframe) == "acousticness_."] <- "acousticness"
names(dataframe)[names(dataframe) == "instrumentalness_."] <- "instrumentalness"
names(dataframe)[names(dataframe) == "liveness_."] <- "liveness"
names(dataframe)[names(dataframe) == "speechiness_."] <- "speechiness"

dataframe = transform(dataframe, liveness = as.numeric(liveness))
dataframe = na.omit(dataframe)

head(dataframe)
```

```{r}
library(tree)
library(randomForest)
library(gbm)
```

## Drzewa decyzyjne

Drzewa decyzyjne są zaimplementowane w pakiecie `tree` (nieco odmienna
implementacja dostępna jest w pakiecie `rpart`).

### Drzewa klasyfikacyjne

Będziemy klasyfikować obserwacje do dwóch klas: *wykonywane na zywo* i *nie wykonywane na żywo*.
Uzupełniamy zbiór danych
```{r}
live <- factor(ifelse(dataframe$liveness <= 50, "No", "Yes"))
dataframeLive <- data.frame(dataframe, live)
```


Budujemy drzewo klasyfikacyjne do predykcji `live` na podstawie pozostałych
zmiennych (poza `liveness` i kilku innych).

```{r}
liveness_high_tree <- tree(live ~ . - track_name - artist.s._name - released_day - in_deezer_playlists - in_shazam_charts - liveness, data = dataframeLive)
summary(liveness_high_tree)
```

Dla drzew klasyfikacyjnych
$$
  \text{deviance} = -2 n \sum_{m=1}^{|T|} \sum_{k=1}^K \hat{p}_{mk} \log \hat{p}_{mk}
$$
oraz
$$
  \text{residual mean deviance} = \frac{\text{deviance}}{n - |T|}.
$$

Przedstawienie graficzne dopasowanego modelu
```{r}
{
plot(liveness_high_tree)
text(liveness_high_tree, pretty = 0)
}
```

Więcej informacji podaje funkcja `print.tree()`
```{r}
liveness_high_tree
```

[**Które predyktory są najbardziej istotne?**]

Metodą zbioru walidacyjnego estymujemy błąd testowy dla drzewa klasyfikacyjnego
w rozważanym problemie.
```{r}
set.seed(1)
n <- nrow(dataframeLive)
train <- sample(n, n / 2)
test <- -train
liveness_high_tree <- tree(live ~ . - track_name - artist.s._name - released_day - in_deezer_playlists - in_shazam_charts - liveness, data = dataframeLive, subset = train)
tree_class <- predict(liveness_high_tree, newdata = dataframeLive[test,], type = "class")
table(tree_class, dataframeLive$live[test])
mean(tree_class != dataframeLive$live[test])
```

*Duże* drzewo $T_0$ dla zbioru uczącego `dataframeLive[train,]`
```{r}
{
plot(liveness_high_tree)
text(liveness_high_tree, pretty = 0)
}
```

Do znalezienia optymalnego poddrzewa stosujemy przycinanie stosowane złożonością.
Przy pomocy CV konstruujemy ciąg poddrzew wyznaczony przez malejącą złożoność.

```{r}
set.seed(1)
liveness_high_cv <- cv.tree(liveness_high_tree, FUN = prune.misclass)
liveness_high_cv
plot(liveness_high_cv$size, liveness_high_cv$dev, type = "b")
```

Składowa `liveness_high_cv$dev` zawiera liczbę błędów CV. Przycinamy drzewo $T_0$
do poddrzewa z najmniejszym poziomem błędów CV.

```{r}
size_opt <- liveness_high_cv$size[which.min(liveness_high_cv$dev)]
# niestety size_opt = 1 i nie da się tego wyświetlić
liveness_high_pruned <- prune.misclass(liveness_high_tree, best = 5)
{
plot(liveness_high_pruned)
text(liveness_high_pruned, pretty = 0)
}
```

Testowy poziom błędów dla optymalnego poddrzewa.
```{r}
pruned_class <- predict(liveness_high_pruned, newdata = dataframeLive[test,], 
                        type = "class")
table(pruned_class, dataframeLive$live[test])
mean(pruned_class != dataframeLive$live[test])
```

[**Narysuj wykres błędu testowego w zależności od rozmiaru poddrzewa.**]

### Drzewa regresyjne

```{r}
liveness_tree <- tree(liveness ~ . - track_name - artist.s._name - released_day - in_deezer_playlists - in_shazam_charts, data = dataframe)
summary(liveness_tree)
```

*Deviance* oznacza tutaj RSS. Przedstawienie drzewa
```{r}
{
liveness_tree
plot(liveness_tree)
text(liveness_tree)
}
```

[**Które predyktory są najistotniejsze?**]

Metodą zbioru walidacyjnego szacujemy błąd testowy.

```{r}
set.seed(1)
n <- nrow(dataframe)
train <- sample(n, n / 2)
test <- -train
liveness_tree <- tree(liveness ~ . - track_name - artist.s._name - released_day - in_deezer_playlists - in_shazam_charts, data = dataframe, subset = train)
liveness_pred <- predict(liveness_tree, newdata = dataframe[test,])
mean((liveness_pred - dataframe$liveness[test])^2)
```
```{r}
{
plot(liveness_tree)
text(liveness_tree)
}
```

Wyznaczamy optymalne poddrzewo metodą przycinania sterowanego złożonością.

```{r}
liveness_cv <- cv.tree(liveness_tree)
plot(liveness_cv$size, liveness_cv$dev, type = "b")
```

[**Które poddrzewo jest optymalne? Jaki jest jego (estymowany) błąd testowy?**]

Przycinanie drzewa $T_0$ do żądanego poziomu realizuje w tym przypadku funkcja
`prune.tree()`.

```{r}
liveness_pruned <- prune.tree(liveness_tree, best = 4)
plot(liveness_pruned)
text(liveness_pruned)
```

[**Oblicz estymatę błędu testowego dla poddrzewa z 4 liśćmi.**]

## Bagging i lasy losowe

Bagging i lasy losowe implementowane są przez pakiet `randomForest`.
Oczywiście bagging jest szczególnym przypadkiem lasu losowego.

### Bagging

Bagging dla regresji `liveness` względem wszystkich pozostałych w zbiorze `dataframe`.

```{r}
liveness_bag <- randomForest(liveness ~ . - track_name - artist.s._name - released_day - in_deezer_playlists - in_shazam_charts, data = dataframe, mtry = 13, importance = TRUE)
liveness_bag
```

Wykres błędu OOB względem liczby drzew
```{r}
plot(liveness_bag, type = "l")
```
W przypadku regresji błąd MSE OOB dostępny jest w składowej `mse` obiektu
klasy `randomForest`.
W przypadku klasyfikacji wyniki analizy danych OOB dostępne są w składowych 
`err.rate` (proporcja błędów) i `confusion` (tabela pomyłek).

Wyznaczenie ważności predyktorów
```{r}
importance(liveness_bag)
```
I stosowny obrazek
```{r}
varImpPlot(liveness_bag)
```

Oszacowanie błędu testowego dla poprzednio wyznaczonego zbioru walidacyjnego.
```{r}
set.seed(2)
liveness_bag <- randomForest(liveness ~ . - track_name - artist.s._name - released_day - in_deezer_playlists - in_shazam_charts, data = dataframe, subset = train, mtry = 13,
                         importance = TRUE)
liveness_pred_bag <- predict(liveness_bag, newdata = dataframe[test,])
mean((liveness_pred_bag - dataframe$liveness[test])^2)
```

[**Czy dla zmniejszonego zbioru uczącego zmieniła się ważność predyktorów?**]

Powyższe dla mniejszej liczby hodowanych drzew
```{r}
set.seed(2)
liveness_bag_s <- randomForest(liveness ~ ., data = dataframe, subset = train, mtry = 13,
                         importance = TRUE, ntree = 25)
liveness_pred_bag_s <- predict(liveness_bag_s, newdata = dataframe[test,])
mean((liveness_pred_bag_s - dataframe$liveness[test])^2)
```

### Lasy losowe

Domyślna wartość parametru `mtry` to $\sqrt{p}$ dla regresji i $p/3$ dla 
klasyfikacji.

Oszacowanie błędu testowego dla poprzednio wyznaczonego zbioru walidacyjnego.
```{r}
set.seed(2)
liveness_rf <- randomForest(liveness ~ . - track_name - artist.s._name - released_day - in_deezer_playlists - in_shazam_charts, data = dataframe, subset = train,
                         importance = TRUE)
liveness_pred_rf <- predict(liveness_rf, newdata = dataframe[test,])
mean((liveness_pred_rf - dataframe$liveness[test])^2)
```

[**Co w tym przypadku można powiedzieć o istotności predyktorów?**]

[**Porównaj na wykresie błędy OOB dla baggingu i domyślnie skonfigurowanego
lasu losowego.**]

Powyższe dla ręcznie ustawionego parametru $m$ (czyli `mtry`).
```{r}
set.seed(2)
liveness_rf <- randomForest(liveness ~ . - track_name - artist.s._name - released_day - in_deezer_playlists - in_shazam_charts, data = dataframe, subset = train, mtry = 6,
                         importance = TRUE)
liveness_pred_rf <- predict(liveness_rf, newdata = dataframe[test,])
mean((liveness_pred_rf - dataframe$liveness[test])^2)
```

## Boosting

Używamy algorytmów boostingu dla drzew decyzyjnych zaimplementowanych w 
pakiecie `gbm`. Inną implementację --- wydajną i często pojawiającą się
w zastosowaniach --- zawiera pakiet `xgboost`.

Boosting dla regresji `liveness` względem pozostałych zmiennych ze zbioru `dataframe`.
Funkcją dopasowującą model jest `gbm()` z istotnymi parametrami:

- `distribution`: `"gaussian"` dla regresji z RSS, `"bernoulli"` dla regresji typu
logistycznego;

- `n.trees`: liczba hodowanych drzew ($B$);

- `interaction.depth`: głębokość interakcji ($d$);

- `shrinkage`: parametr spowalniający uczenie ($\lambda$).

```{r}
liveness_boost <- gbm(liveness ~ . - track_name - artist.s._name - released_day - in_deezer_playlists - in_shazam_charts - streams - key - mode, data = dataframe, distribution = "gaussian",
                  n.trees = 5000, interaction.depth = 4)
liveness_boost
```

Funkcja `summary.gbm()` wyznacza ważność predyktorów i (domyślnie) wykonuje
odpowiedni wykres.
```{r}
summary(liveness_boost)
```

[**Które predyktory teraz są najistotniejsze?**]

Funkcja `plot.gbm()` wykonuje *wykresy częściowej zaleźności*.
```{r}
plot(liveness_boost, i.var = "acousticness")
plot(liveness_boost, i.var = "energy")
plot(liveness_boost, i.var = c("acousticness", "energy"))
```

Oszacowanie błędu testowego dla poprzednio wyznaczonego zbioru walidacyjnego.
```{r}
set.seed(2)
liveness_boost <- gbm(liveness ~ . - track_name - artist.s._name - released_day - in_deezer_playlists - in_shazam_charts - streams - key - mode, data = dataframe[train,], distribution = "gaussian",
                  interaction.depth = 4, n.trees = 5000)
liveness_pred_boost <- predict(liveness_boost, newdata = dataframe[test,], n.trees = 5000)
mean((liveness_pred_boost - dataframe$liveness[test])^2)
```

To samo dla $\lambda = 0.01$.
```{r}
set.seed(2)
liveness_boost <- gbm(liveness ~ . - track_name - artist.s._name - released_day - in_deezer_playlists - in_shazam_charts - streams - key - mode, data = dataframe[train,], distribution = "gaussian",
                  interaction.depth = 4, n.trees = 5000, shrinkage = 0.01)
liveness_pred_boost <- predict(liveness_boost, newdata = dataframe[test,], n.trees = 5000)
mean((liveness_pred_boost - dataframe$liveness[test])^2)
```

To samo dla $d = 1$.
```{r}
set.seed(2)
liveness_boost <- gbm(liveness ~ . - track_name - artist.s._name - released_day - in_deezer_playlists - in_shazam_charts - streams - key - mode, data = dataframe[train,], distribution = "gaussian",
                  n.trees = 5000, shrinkage = 0.01)
liveness_pred_boost <- predict(liveness_boost, newdata = dataframe[test,], n.trees = 5000)
mean((liveness_pred_boost - dataframe$liveness[test])^2)
```

[**Użyj baggingu, lasów losowych i boostingu do analizy problemu klasyfikacji
sprzedaży w zbiorze `dataframeLive`. Jak zastosowanie tych metod wpływa na
jakość klasyfikacji? Co można powiedzieć o ważności predyktorów?**]

**Uwaga**. Obecna implementacja funkcji `gbm()` nie działa jeśli
zmienna odpowiedzi jest czynnikiem o 2 poziomach. Należy taką zmienną
przekształcić na zmienną numeryczną o wartościach w zbiorze $\{0, 1\}$
lub na zmienną logiczną. Np. w powyższym ćwiczeniu zamiast zmiennej `live`
można użyć `I(live == "Yes")`.
