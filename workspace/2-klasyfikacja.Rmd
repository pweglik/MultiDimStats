---
title: "Podstawowe metody klasyfikacji"
date: "Semestr letni 2021/22"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
library(MASS)
library(ISLR)
library(class)
```

## Dane

W trakcie zajęć wykorzystywany będzie zbiór danych `Smarket` z pakietu `ISLR`.
Opisuje on zachowanie indeksu giełdowego S&P 500 przez kolejne dni od
roku 2001 do roku 2005. Zmienna `Direction` jest czynnikiem o 2 poziomach
podsumowującym kierunek zmiany indeksu w danym dniu, tzn. `Direction == "Up"`
wtedy i tylko wtedy, gdy `Today >= 0`. [**Sprawdź**]

Obliczenie korelacji zmiennych numerycznych (innych niż `Direction`)
```{r cor}
cor(Smarket[-9])
```
wskazuje na to, że zauważalna korelacja występuje tylko między zmiennymi
`Year` i `Volume`. Wykres rozproszenia
```{r plotVolume}
plot(Smarket$Volume)
```
pokazuje, że `Volume` rośnie w czasie.

## Regresja logistyczna

Chcemy dopasować model regresji logistycznej
żeby przewidzieć wartość `Direction` na podstawie zmiennych
`Lag1`, ..., `Lag5` i `Volume`.

```{r logistic}
dir_logistic <- list()
dir_logistic$fit <- glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, 
                   family = binomial, data = Smarket)
summary(dir_logistic$fit)
```

[**Zinterpretuj wyniki**]

Do predykcji --- podobnie jak w regresji liniowej --- wykorzystywana jest
funkcja `predict()`. Przy wartości parametru `type = "response"` funkcja zwraca
przewidywane prawdopodobieństwa $P(Y = 1 | X)$ (a nie np. szanse logarytmiczne).
```{r logisticPredictProbs}
dir_logistic$probs <- predict(dir_logistic$fit, type = "response")
head(dir_logistic$probs)
```

Warto się upewnić czy $Y = 1$ oznacza `Direction == "Up"`
```{r logisticContrasts}
contrasts(Smarket$Direction)
```

Ostatecznie przewidywane przypisanie do klas uzyskujemy stosując bayesowską
regułę decyzyjną (*maximum a posteriori*).
```{r logisticClass}
dir_logistic$predicted <- ifelse(dir_logistic$probs > 0.5, "Up", "Down")
```

Do zobrazowania wyników klasyfikacji używamy *tablicy pomyłek*
(*confusion matrix*)
```{r logisticConfusionMatrix}
dir_logistic$cm <- table(dir_logistic$predicted, Smarket$Direction)
dir_logistic$cm
```

*Proporcję błędów* można policzyć np. na jeden z poniższych sposobów.
```{r logisticErrorRate}
(dir_logistic$cm[1, 2] + dir_logistic$cm[2, 1]) / sum(dir_logistic$cm)
mean(dir_logistic$predicted != Smarket$Direction)
```

Niestety powyższa proporcja błędów jest *treningową proporcją błędów*.
Do estymacji *testowej proporcji błędów* zastosujemy podział dostępnych danych
na:

- zbiór uczący --- dane od 2001 do 2004 roku;

- zbiór testowy --- dane z 2005 roku.

```{r trainAndTestSets}
train <- Smarket$Year < 2005
Smarket_test <- Smarket[!train,]
Direction_test <- Smarket$Direction[!train]
```

Regresję wykonujemy na podstawie zbioru uczącego
```{r logisticTrain}
dir_log_t <- list()
dir_log_t$fit <- glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, 
                   family = binomial, data = Smarket, subset = train)
summary(dir_log_t$fit)
```
a otrzymany model wykorzystujemy do predykcji dla danych ze zbioru testowego
```{r logisticPredictionTrain}
dir_log_t$probs <- predict(dir_log_t$fit, Smarket_test, type = "response")
dir_log_t$predicted <- ifelse(dir_log_t$probs > 0.5, "Up", "Down")
table(dir_log_t$predicted, Direction_test)
```

[**Jaka jest zatem proporcja błędów dla takiego zbioru testowego?**]

Próbujemy uzyskać bardziej efektywny model eliminując najmniej istotne predyktory
--- wszystkie mają słabe lub bardzo słabe $p$-wartości, ale najlepsze dwa
to `Lag1` i `Lag2`.
```{r logisticSmall}
dir_log_best2 <- list()
dir_log_best2$fit <- glm(Direction ~ Lag1 + Lag2, family = binomial, 
                    data = Smarket, subset = train)
summary(dir_log_best2$fit)
dir_log_best2$probs <- predict(dir_log_best2$fit, Smarket_test, type = "response")
dir_log_best2$predicted <- ifelse(dir_log_best2$probs > 0.5, "Up", "Down")
table(dir_log_best2$predicted, Direction_test)
```

[**Jak w tym przypadku wygląda proporcja błędów? Jak wygląda jej porównanie
z proporcją błędów naiwnej strategii przewidującej wzrost zawsze?**]
```{r naivePred}
mean(Direction_test != "Up")
```

[**Jaką strategię inwestowania można zasugerować na podstawie ostatniej tabeli
pomyłek?**]

## LDA i QDA

Funkcje `lda()` i `qda()` są zaimplementowane w pakiecie `MASS`.

### LDA

W sytuacji jak poprzednio stosujemy LDA do klasyfikacji wyznaczonej przez
`Direction` względem `Lag1` i `Lag2`.
```{r lda}
dir_lda <- list()
dir_lda$fit <- lda(Direction ~ Lag1 + Lag2, data = Smarket, subset = train)
dir_lda$fit
```

Predykcję wykonuje funkcja `predict.lda()`. Zwraca ona listę, której komponentami
są: wektor przewidywanych klas `class`, wektor prawdopodobieństw a posteriori 
`posterior` i wektor wartości liniowego dyskryminatora `x`.
```{r ldaPredict}
dir_lda$predicted <- predict(dir_lda$fit, Smarket_test)
table(dir_lda$predicted$class, Direction_test)
```

[**Jak wygląda porównanie wyniku klasyfikacji LDA z regresją logistyczną?**]

Maksymalne przewidywane prawdopodobieństwo wzrostu w 2005
```{r ldaMaxProbUp}
max(dir_lda$predicted$posterior[, 2])
```

Maksymalne przewidywane prawdopodobieństwo spadku w 2005
```{r ldaMaxProbDown}
max(dir_lda$predicted$posterior[, 1])
```

### QDA

Ten sam problem z kwadratowym dyskryminatorem
```{r qda}
dir_qda <- list()
dir_qda$fit <- qda(Direction ~ Lag1 + Lag2, data = Smarket, subset = train)
dir_qda$fit
```

I predykcja
```{r qdaPredict}
dir_qda$predicted <- predict(dir_qda$fit, Smarket_test)
table(dir_qda$predicted$class, Direction_test)
```

[**Jaka jest w tym przypadku proporcja błędów?**]

## kNN

W tym przypadku nie ma jawnego etapu dopasowania. Funkcja `knn()` z pakietu
`class` od razu wykonuje predykcję. Np. ze zbiorem uczącym i testowym jak
poprzednio i z $k = 1$ mamy
```{r knn}
train_set <- Smarket[train, c("Lag1", "Lag2")]
test_set <- Smarket[!train, c("Lag1", "Lag2")]
Direction_train <- Smarket$Direction[train]
dir_knn_1 <- knn(train_set, test_set, Direction_train, k = 1)
table(dir_knn_1, Direction_test)
```

Ze względu na to, że kNN rozstrzyga remisy losowo, dla zapewnienia powtarzalności
wyników warto przed wywołaniem funkcji `knn` zainicjalizować generator liczb
pseudolosowych (`?set.seed`).

Proporcja błędów dla kNN z $k = 1$ nie jest imponująca
```{r knnError}
mean(dir_knn_1 != Direction_test)
```

[**Jak wygląda proporcja błędów dla $k = 3$? A dla większych $k$?**]
